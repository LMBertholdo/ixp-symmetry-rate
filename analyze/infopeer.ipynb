{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How regional are the peers on each IXP?\n",
    "<pre>\n",
    " Considering each IXP participant on IXP open peering and the region each AS is registered \n",
    " How regional are the neighbors?\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly \n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import fnmatch\n",
    "from datetime import date, datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download routing tables to this folder\n",
    "BGP_DATA  = \"/Users/bertholdo/tmp/Routing_Tables/\"      \n",
    "# Output images \n",
    "IMAGE_DIR = \"/Users/bertholdo/PAPERS/asym/leandro/\"\n",
    "# in/out datasets\n",
    "DATASET   = \"/Users/bertholdo/ut_gitlab/asy_pathsize/dataset/\"\n",
    "\n",
    "version='1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_jupyter_notebook():\n",
    "    ''' Return True if is running inside Jupyter Notebook or Jupyter lab '''\n",
    "    try:\n",
    "        __IPYTHON__\n",
    "        _in_ipython_session = True\n",
    "    except NameError:\n",
    "        _in_ipython_session = False\n",
    "    return _in_ipython_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from urllib import request\n",
    "from contextlib import closing\n",
    "\n",
    "def download_url(url='',dstDir=''):   \n",
    "    # if url is abc/xyz/file.txt, the dstFile will be file.txt\n",
    "    dstFile = dstDir + url.rsplit('/',1)[1]\n",
    "        \n",
    "    #print(\"downloading FROM:\",url, \"TO\", dstFile)\n",
    "    with closing(request.urlopen(url)) as src:\n",
    "        with open(dstFile, 'wb') as dst:\n",
    "            shutil.copyfileobj(src, dst)\n",
    "            \n",
    "    return dstFile;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "\n",
    "def download_rir_files(rir_dir='./Dados_RIR/'):\n",
    "    rir_url =['ftp://ftp.lacnic.net:/pub/stats/lacnic/delegated-lacnic-extended-latest',\n",
    "              'ftp://ftp.afrinic.net:/pub/stats/afrinic/delegated-afrinic-extended-latest',\n",
    "              'ftp://ftp.arin.net:/pub/stats/arin/delegated-arin-extended-latest',\n",
    "              'ftp://ftp.apnic.net:/public/apnic/stats/apnic/delegated-apnic-extended-latest',\n",
    "              'ftp://ftp.ripe.net:/pub/stats/ripencc/delegated-ripencc-extended-latest']\n",
    "     \n",
    "    if not os.path.exists(rir_dir):\n",
    "        os.makedirs(rir_dir)\n",
    "    \n",
    "    # simple download\n",
    "    #for url in rir_url:\n",
    "    #    file = rir_dir + url.rsplit('/',1)[1]\n",
    "    #    download_url(url,file)\n",
    " \n",
    "    # paralled download\n",
    "    # Prepare one param to ThreadPool (partial to join parms)\n",
    "    call_funct_param=partial(download_url, dstDir=rir_dir)\n",
    "  \n",
    "    # Start Thread for download URL\n",
    "    results = ThreadPool(8).imap_unordered(call_funct_param, rir_url)\n",
    "    \n",
    "    # Wait to finish\n",
    "    for path in results:\n",
    "        print(\"Downloaded to: \", path)\n",
    "              \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rir_description( descr ):\n",
    "    if 'RIPE' in descr:\n",
    "        return 'ripencc'\n",
    "    elif 'APNIC' in descr:\n",
    "        return 'apnic'\n",
    "    elif 'AFRINIC' in descr:\n",
    "        return 'afrinic'\n",
    "    elif 'LACNIC' in descr:\n",
    "        return 'lacnic'\n",
    "    elif 'ARIN' in descr:\n",
    "        return 'arin'\n",
    "    elif 'Reserved' in descr or 'AS_TRANS' in descr:\n",
    "        return 'Reserved'\n",
    "    else:\n",
    "        print ('RIR_DESCRIPTION:: Not know -->', descr)\n",
    "\n",
    "def rir_iana_delegation():\n",
    "    '''Return a dataframe from all ASNs alocated to each RIR from IANA'''   \n",
    "    \n",
    "    asn16bits=\"https://www.iana.org/assignments/as-numbers/as-numbers-1.csv\"\n",
    "    asn32bits=\"https://www.iana.org/assignments/as-numbers/as-numbers-2.csv\"\n",
    "    mydict={}\n",
    "\n",
    "    for url in [asn16bits, asn32bits]:\n",
    "        #print (url)\n",
    "        iana=pd.read_csv(url)\n",
    "        for index,row in iana.iterrows():\n",
    "            if any (x in row['Description'] for x in ['16-bit AS numbers','Unallocated','Reserved','AS_TRANS']):\n",
    "                continue\n",
    "            if '-' in row['Number']:\n",
    "                start,end=[int(n) for n in row['Number'].split('-')]\n",
    "                for n in range (start,end):\n",
    "                    if not n in mydict.keys():\n",
    "                        mydict[n]=rir_description(row['Description'])\n",
    "                    else:\n",
    "                        print('tem-->', n)\n",
    "            else:\n",
    "                n=int(row['Number'])\n",
    "                if not n in mydict.keys():\n",
    "                    mydict[n]=rir_description(row['Description'])\n",
    "                else:\n",
    "                    print('ja tem')\n",
    "                    \n",
    "    df=pd.DataFrame.from_dict(mydict, orient='index', columns=['RIR'])\n",
    "    df['ASN'] = df.index\n",
    "    df=df.reset_index()\n",
    "    \n",
    "    return (df[['ASN','RIR']])\n",
    "\n",
    "def rir_asn_delegation():\n",
    "    ''' Read ASN info from RIR files in a dataframe pandas'''\n",
    "\n",
    "    # Download last version of rir data\n",
    "    data_RIR='./Dados_RIR/'\n",
    "    download_rir_files(data_RIR)\n",
    "\n",
    "    # Read all RIR files\n",
    "    rir_df=pd.DataFrame()\n",
    "    for file in os.listdir(data_RIR):\n",
    "        print (\"Appending..\", file)\n",
    "        rir_database_path=data_RIR+file\n",
    "        #print (rir_database_path)\n",
    "        headers = ['Registry', 'Country Code', 'Type', 'Start', 'Value', 'Date', 'Status', 'Extensions']\n",
    "        tmp_df = pd.read_csv(rir_database_path, delimiter='|', comment='#', names=headers, dtype=str, \n",
    "                             keep_default_na=False, na_values=[''],encoding='utf-8')[4:]\n",
    "        #rir_df=rir_df.append(tmp_df)\n",
    "        rir_df=pd.concat([rir_df,tmp_df])\n",
    "    \n",
    "    #filter rir_df fields  (asn,rir)\n",
    "    df=rir_df[rir_df['Type']=='asn']\n",
    "    df=df.filter(['Start','Registry'])\n",
    "    df=df.drop_duplicates()\n",
    "    df.columns = ['ASN','RIR']\n",
    "    df[\"ASN\"]=pd.to_numeric(df[\"ASN\"])\n",
    "    \n",
    "    return (df.reset_index(drop=True))\n",
    "\n",
    "def asn_allocation_rir_iana():\n",
    "    ''' Get all ASNs information about region, including IANA reserve for RIRs'''\n",
    "    df1=rir_asn_delegation()\n",
    "    df2=rir_iana_delegation()\n",
    "\n",
    "    df=pd.concat([df1,df2]).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to:  ./Dados_RIR/delegated-arin-extended-latest\n",
      "Downloaded to:  ./Dados_RIR/delegated-lacnic-extended-latest\n",
      "Downloaded to:  ./Dados_RIR/delegated-afrinic-extended-latest\n",
      "Downloaded to:  ./Dados_RIR/delegated-ripencc-extended-latest\n",
      "Downloaded to:  ./Dados_RIR/delegated-apnic-extended-latest\n",
      "Appending.. delegated-afrinic-extended-latest\n",
      "Appending.. delegated-arin-extended-latest\n",
      "Appending.. delegated-apnic-extended-latest\n",
      "Appending.. delegated-ripencc-extended-latest\n",
      "Appending.. delegated-lacnic-extended-latest\n"
     ]
    }
   ],
   "source": [
    "df_rir=asn_allocation_rir_iana()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Values from [amsix] ====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ripencc    0.745935\n",
       "arin       0.134146\n",
       "apnic      0.083333\n",
       "afrinic    0.018293\n",
       "lacnic     0.018293\n",
       "Name: RIR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==== Values from [spoixbr] ====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lacnic     0.927386\n",
       "arin       0.055498\n",
       "ripencc    0.012448\n",
       "apnic      0.003631\n",
       "afrinic    0.001037\n",
       "Name: RIR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==== Values from [six] ====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "arin       0.849515\n",
       "ripencc    0.092233\n",
       "apnic      0.058252\n",
       "Name: RIR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==== Values from [linx] ====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ripencc    0.734783\n",
       "arin       0.123913\n",
       "apnic      0.080435\n",
       "afrinic    0.058696\n",
       "lacnic     0.002174\n",
       "Name: RIR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==== Values from [poaixbr] ====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lacnic     0.914530\n",
       "arin       0.081197\n",
       "ripencc    0.004274\n",
       "Name: RIR, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ixp_list=['amsix','spoixbr','six','linx','poaixbr']\n",
    "\n",
    "for ixp in ixp_list:\n",
    "    for f in glob.glob(f'peerinfo/*_{ixp}.csv.gz'):\n",
    "        df = pd.read_csv(f)\n",
    "        #df = df_asnlst[(df_asnlst['policy'].str.upper()=='OPEN') & (df_asnlst['state'].str.upper()=='UP')]\n",
    "        #ixp_asn_lst = df_asnlst['ASN'].unique().tolist()\n",
    "        #df=df[df['as_neigh'].isin(ixp_asn_lst)]\n",
    "    \n",
    "        #df=pd.read_csv(f'peerinfo/2022-05-05_peerinfo_br-gru_spoixbr.csv.gz')\n",
    "        df=df[(df['policy'].str.upper()=='OPEN') & (df['state'].str.upper()=='UP')]\n",
    "        df=df[['ASN','organization']]\n",
    "        df_peer=df.drop_duplicates()\n",
    "    \n",
    "        # Where are from each peer?\n",
    "        nei_list = df_peer['ASN'].to_list()\n",
    "        df=df_rir[df_rir['ASN'].isin(nei_list)]\n",
    "        \n",
    "        # Contabil\n",
    "        print(f'==== Values from [{ixp}] ====')\n",
    "        display(df['RIR'].value_counts(ascending=False, normalize=True))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
